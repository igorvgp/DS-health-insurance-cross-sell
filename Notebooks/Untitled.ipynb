{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df2c564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T12:30:17.461520Z",
     "start_time": "2023-02-14T12:27:16.213065Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from xgboost  import XGBClassifier\n",
    "from sqlalchemy              import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.preprocessing   import MinMaxScaler\n",
    "from sqlalchemy.sql          import text\n",
    "from sqlalchemy              import create_engine\n",
    "\n",
    "####### Helper Functions #########\n",
    "\n",
    "def score_top_k(y_test, predict_proba, top_k):\n",
    "    df = pd.DataFrame()\n",
    "    df['predictions'] = predict_proba[:,1]\n",
    "    df['y_test'] = y_test.values\n",
    "    df = df.sort_values('predictions', ascending = False).reset_index(drop = True).reset_index()\n",
    "    df['score'] = df.apply(lambda x: 1 if ( x['index'] <= top_k and x['y_test'] == 1) else 0, axis = 1 )\n",
    "    precision = df['score'].sum() / top_k\n",
    "    recall = df['score'].sum() / df['y_test'].sum()\n",
    "    return {'precision': precision, 'recall': recall}\n",
    "\n",
    "\n",
    "####### Engine to connect database ##########\n",
    "engine = create_engine('postgresql+psycopg2://member:cdspa@comunidade-ds-postgres.c50pcakiuwi3.us-east-1.rds.amazonaws.com/comunidadedsdb')\n",
    "conn = engine.connect()\n",
    "\n",
    "query = '''\n",
    "        SELECT \n",
    "              pu.id,\n",
    "              gender,\n",
    "              age,\n",
    "              region_code,\n",
    "              policy_sales_channel,\n",
    "              previously_insured,\n",
    "              annual_premium,\n",
    "              vintage,\n",
    "              response,\n",
    "              driving_license,\n",
    "              vehicle_age,\n",
    "              vehicle_damage\n",
    "            \n",
    "        FROM\n",
    "              pa004.users pu\n",
    "              LEFT JOIN pa004.insurance pi ON (pi.id = pu.id)\n",
    "              LEFT JOIN pa004.vehicle pv ON (pi.id = pv.id);\n",
    "'''\n",
    "\n",
    "with conn.execution_options(autocommit=True) as conn:\n",
    "    query = conn.execute(text(query))\n",
    "   \n",
    "df = pd.DataFrame(query.fetchall())\n",
    "df.columns = ['id','gender','age','region_code','policy_sales_channel','previously_insured',\n",
    "              'annual_premium','vintage','response','driving_license','vehicle_age','vehicle_damage']\n",
    "\n",
    "conn.close()\n",
    "\n",
    "X = df.drop('response', axis = 1)\n",
    "y = df['response']\n",
    "\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2)\n",
    "\n",
    "######## Preprocessing ##########\n",
    "\n",
    "# Age\n",
    "mms_age = MinMaxScaler()\n",
    "X_train['age'] = mms_age.fit_transform(X_train[['age']].values )\n",
    "#pickle.dump( mms_age, open( '../src/parameter/mms_age.pkl', 'wb' ) )\n",
    "X_test['age'] = mms_age.transform(X_test[['age']].values )\n",
    "\n",
    "# Vintage\n",
    "mms_vintage = MinMaxScaler()\n",
    "X_train['vintage'] = mms_vintage.fit_transform(X_train[['vintage']].values )\n",
    "#pickle.dump( mms_vintage, open( '../src/parameter/mms_vintage.pkl', 'wb' ) )\n",
    "X_test['vintage'] = mms_vintage.transform(X_test[['vintage']].values )\n",
    "\n",
    "# Annual premium\n",
    "ss_annual_premium = StandardScaler()\n",
    "X_train['annual_premium'] = ss_annual_premium.fit_transform(X_train[['annual_premium']].values )\n",
    "#pickle.dump( ss_annual_premium, open( '../src/parameter/ss_annual_premium.pkl', 'wb' ) )\n",
    "X_test['annual_premium'] = ss_annual_premium.transform(X_test[['annual_premium']].values )\n",
    "\n",
    "# Vehicle damage\n",
    "X_train['vehicle_damage'] = X_train['vehicle_damage'].apply(lambda x: 0 if x == 'No' else 1)\n",
    "X_test['vehicle_damage'] = X_test['vehicle_damage'].apply(lambda x: 0 if x == 'No' else 1)\n",
    "\n",
    "# region_code \n",
    "aux = X_train.copy()\n",
    "aux['response'] = y\n",
    "target_encoding_region_code = aux.groupby('region_code')['response'].mean()\n",
    "#target_encoding_region_code.to_csv('../src/parameter/target_encoding_region_code.csv', index = True )\n",
    "X_train['region_code'] = X_train['region_code'].map( target_encoding_region_code )\n",
    "X_train['region_code'].fillna(0, inplace = True)\n",
    "X_test['region_code'] = X_test['region_code'].map( target_encoding_region_code )\n",
    "X_test['region_code'].fillna(0, inplace = True)\n",
    "\n",
    "# Gender\n",
    "X_train['gender'] = X_train['gender'].apply(lambda x: 0 if x == 'Male' else 1)\n",
    "X_test['gender'] = X_test['gender'].apply(lambda x: 0 if x == 'Male' else 1)  \n",
    "  \n",
    "# Vehicle age\n",
    "X_train['vehicle_age'] = X_train['vehicle_age'].apply(lambda x: 0 if x == '< 1 Year' else 1 if x == '1-2 Year' else 2)  \n",
    "X_test['vehicle_age'] = X_test['vehicle_age'].apply(lambda x: 0 if x == '< 1 Year' else 1 if x == '1-2 Year' else 2)  \n",
    "\n",
    "# policy sales channel\n",
    "frequency_encoding_policy_sales = aux.groupby('policy_sales_channel')['response'].count() / len(X)\n",
    "#frequency_encoding_policy_sales.to_csv('../src/parameter/frequency_encoding_policy_sales.csv', index = True )\n",
    "X_train['policy_sales_channel'] = X_train['policy_sales_channel'].map( frequency_encoding_policy_sales )\n",
    "X_train['policy_sales_channel'].fillna(0, inplace = True)\n",
    "X_test['policy_sales_channel'] = X_test['policy_sales_channel'].map( frequency_encoding_policy_sales )\n",
    "X_test['policy_sales_channel'].fillna(0, inplace = True)\n",
    "\n",
    "######## Feature selection ##########\n",
    "X_train = X_train[['age', 'region_code', 'policy_sales_channel', 'previously_insured', 'annual_premium', 'vintage', 'vehicle_damage']]\n",
    "X_test = X_test[['age', 'region_code', 'policy_sales_channel', 'previously_insured', 'annual_premium', 'vintage', 'vehicle_damage']]\n",
    "\n",
    "######## Create ML Model ##########\n",
    "\n",
    "params = {'max_depth': 8,\n",
    "         'learning_rate': 0.014416504517463456,\n",
    "         'n_estimators': 499,\n",
    "         'min_child_weight': 10,\n",
    "         'scale_pos_weight': 10,\n",
    "         'gamma': 0.5834982442488319,\n",
    "         'subsample': 0.3703846362615623,\n",
    "         'colsample_bytree': 0.6808135028844782,\n",
    "         'reg_alpha': 1.001572471362163e-05,\n",
    "         'reg_lambda': 1.1690461872764534e-05}\n",
    "\n",
    "########## Train model #############\n",
    "xgb_model = XGBClassifier(**params).fit(X_train, y_train)\n",
    "\n",
    "# Save model pkl\n",
    "#pickle.dump( xgb_model, open( '../src/model/xgb_model.pkl', 'wb' ) )\n",
    "\n",
    "top_k = 2000\n",
    "\n",
    "######### Evaluate model ###########\n",
    "results = score_top_k(y_test, xgb_model.predict_proba(X_test), top_k)\n",
    "\n",
    "date = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "results = [top_k, results['precision'], results['recall'], date]\n",
    "\n",
    "df_results = pd.DataFrame(results).T\n",
    "df_results.columns = ['top_k','precision', 'recall', 'datetime']\n",
    "\n",
    "######### Save results ############\n",
    "\n",
    "# create table\n",
    "query_create_table = '''\n",
    "        CREATE TABLE results (\n",
    "                                top_k     INTEGER,\n",
    "                                precision REAL,\n",
    "                                recall    REAL,\n",
    "                                datetime  TEXT\n",
    "        )\n",
    "'''\n",
    "\n",
    "# Connect to database and create table\n",
    "conn = sqlite3.connect( 'results/results_db.sqlite' )\n",
    "cursor = conn.execute( query_create_table )\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "# Insert data into table\n",
    "conn = sqlite3.connect( 'results/results_db.sqlite' )\n",
    "df_results.to_sql( 'results', con = conn, if_exists = 'append', index = False)\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
